#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import json
from .utils import logger
from .wiki_image_parser import get_image_url_from_wiki

class EnhancedPerplexityExtractor:
    """ì™„ì „ ê°œì„ ëœ Perplexity ê¸°ë°˜ BG3 ìš©ì–´ ì¶”ì¶œ ë° ì´ë¯¸ì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ê°•í™”ëœ BG3 ìš©ì–´ ì¶”ì¶œ íŒ¨í„´ë“¤
        self.bg3_patterns = [
            # 1. ê´„í˜¸ ì•ˆì˜ ì˜ë¬¸ëª… (ê°€ì¥ ì •í™•í•œ íŒ¨í„´)
            r'[ê°€-í£\s]+\s*\(([A-Z][A-Za-z\s\'\-&]+)\)',
            
            # 2. ì½œë¡  ë’¤ì˜ ì˜ë¬¸ëª…ë“¤
            r':\s*([A-Z][A-Za-z\s\'\-&]+(?:\s*\([A-Z][A-Za-z\s]+\))?)',
            
            # 3. BG3 íŠ¹í™” ì¥ë¹„ëª… íŒ¨í„´ (of, the í¬í•¨)
            r'\b((?:The\s+)?[A-Z][a-z]+(?:\s+of\s+[A-Z][a-z]+)+)\b',
            r'\b([A-Z][a-z]+\s+(?:Splint\s+)?Armor)\b',
            r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\s+(?:Staff|Helm|Boots|Cloak|Ring|Amulet))\b',
            
            # 4. BG3 ì£¼ë¬¸ëª… íŒ¨í„´ë“¤ 
            r'\b([A-Z][a-z]+\s+(?:Wounds|Word|Flame|Guardians|Ward|Strike|Intervention|Feast))\b',
            r'\b((?:Mass\s+)?[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*(?:\s+Word|Wounds))\b',
            r'\b([A-Z][a-z]+\s+(?:Domain|Dwarf|Artisan|Caster))\b',
            
            # 5. ì¼ë°˜ BG3 ìš©ì–´ (2-4 ë‹¨ì–´)
            r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,3})\b',
            
            # 6. ëŠ¥ë ¥ì¹˜ ë° ìŠ¤í‚¬
            r'\b(Guidance|Resistance|Bless|Aid)\b',
        ]
        
        # ì œì™¸í•  ë‹¨ì–´ë“¤ (ë” ì •êµí•˜ê²Œ)
        self.excluded_terms = {
            'general': ['Game', 'Build', 'Guide', 'Level', 'Act', 'Patch', 'User', 'Community', 
                       'Expert', 'Best', 'Top', 'Main', 'New', 'Latest', 'Update', 'Version'],
            'korean': ['ê¸°ì¤€', 'ì ìš©', 'ì´ìœ ', 'ë¬´ë£Œ', 'íšë“', 'ê¸°ë°˜', 'ì‚¬ìš©', 'íš¨ê³¼', 'ìƒí™©'],
            'numbers': ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA', 'AC', 'DC'],
            'common': ['This', 'That', 'With', 'From', 'When', 'Where', 'What', 'How', 'Why']
        }
        
        # BG3 í™•ì‹¤í•œ ìš©ì–´ë“¤ (ë†’ì€ ìš°ì„ ìˆœìœ„)
        self.bg3_confirmed_terms = {
            'spells': ['Guidance', 'Resistance', 'Cure Wounds', 'Bless', 'Healing Word', 'Aid', 
                      'Spiritual Weapon', 'Sacred Flame', 'Spirit Guardians', 'Mass Healing Word',
                      'Death Ward', 'Storm Sphere', 'Divine Strike', 'Mass Cure Wounds', 
                      'Divine Intervention', 'Heroes Feast'],
            'equipment': ['Adamantine Splint Armor', 'Amulet of Greater Health', 'Staff of Arcane Blessing',
                         'Helm of Brilliance', 'Boots of Reactionary Defense', 'Cloak of Protection',
                         'Ring of Regeneration'],
            'classes': ['Life Domain', 'Shield Dwarf', 'Guild Artisan', 'War Caster'],
            'abilities': ['Preserve Life', 'Channel Divinity']
        }
    
    def extract_bg3_terms_from_perplexity(self, perplexity_content):
        """ê°•í™”ëœ BG3 ìš©ì–´ ì¶”ì¶œ"""
        logger.info("ğŸ” ê°•í™”ëœ Perplexity BG3 ìš©ì–´ ì¶”ì¶œ ì‹œì‘")
        
        all_terms = set()
        priority_terms = set()
        extraction_stats = {}
        
        # 1. í™•ì‹¤í•œ BG3 ìš©ì–´ë“¤ ë¨¼ì € ì°¾ê¸°
        for category, terms in self.bg3_confirmed_terms.items():
            for term in terms:
                if term in perplexity_content:
                    priority_terms.add(term)
                    logger.info(f"âœ… í™•ì¸ëœ BG3 ìš©ì–´ ë°œê²¬: {term}")
        
        # 2. íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ
        for i, pattern in enumerate(self.bg3_patterns, 1):
            matches = re.findall(pattern, perplexity_content, re.MULTILINE | re.IGNORECASE)
            valid_matches = []
            
            for match in matches:
                if isinstance(match, tuple):
                    term = match[0] if match[0] else (match[1] if len(match) > 1 else '')
                else:
                    term = match
                
                term = term.strip()
                
                # ìœ íš¨ì„± ê²€ì¦
                if self.is_valid_bg3_term(term):
                    all_terms.add(term)
                    valid_matches.append(term)
            
            extraction_stats[f"íŒ¨í„´_{i}"] = {
                "total": len(matches),
                "valid": len(valid_matches),
                "sample": valid_matches[:3]
            }
            
            logger.info(f"íŒ¨í„´ {i}: {len(valid_matches)}/{len(matches)} ìœ íš¨")
        
        # 3. ìš°ì„ ìˆœìœ„ ìš©ì–´ì™€ ì¼ë°˜ ìš©ì–´ í•©ì¹˜ê¸°
        final_terms = list(priority_terms) + [term for term in all_terms if term not in priority_terms]
        
        logger.info(f"ì´ ì¶”ì¶œëœ BG3 ìš©ì–´: {len(final_terms)}ê°œ (ìš°ì„ ìˆœìœ„: {len(priority_terms)}ê°œ)")
        
        if final_terms:
            logger.info(f"ìƒ˜í”Œ ìš©ì–´ë“¤: {', '.join(final_terms[:10])}...")
        
        return final_terms, extraction_stats
    
    def is_valid_bg3_term(self, term):
        """ê°œì„ ëœ BG3 ìš©ì–´ ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(term) < 3 or len(term) > 50:
            return False
        
        # ì œì™¸ ë‹¨ì–´ ì²´í¬
        for category, excluded in self.excluded_terms.items():
            if term in excluded:
                return False
        
        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if term.isdigit() or re.match(r'^\d+$', term):
            return False
        
        # í•œê¸€ í¬í•¨ ì œì™¸
        if re.search(r'[ê°€-í£]', term):
            return False
        
        # ë„ˆë¬´ ë§ì€ íŠ¹ìˆ˜ë¬¸ì ì œì™¸
        special_chars = len(re.findall(r'[^A-Za-z\s\'\-&]', term))
        if special_chars > 2:
            return False
        
        # BG3 ìŠ¤ëŸ¬ìš´ íŒ¨í„´ë“¤
        # 1. í™•ì‹¤í•œ BG3 ìš©ì–´
        for category, terms in self.bg3_confirmed_terms.items():
            if term in terms:
                return True
        
        # 2. ì²« ê¸€ì ëŒ€ë¬¸ì + ì ì ˆí•œ ê¸¸ì´
        if re.match(r'^[A-Z][a-z]', term) and len(term) >= 4:
            return True
        
        # 3. "X of Y" íŒ¨í„´
        if re.match(r'^[A-Z][a-z]+\s+of\s+[A-Z]', term):
            return True
        
        # 4. ë³µí•© ë‹¨ì–´ (ëª¨ë“  ë‹¨ì–´ê°€ ëŒ€ë¬¸ìë¡œ ì‹œì‘)
        words = term.split()
        if len(words) >= 2 and all(word[0].isupper() for word in words if len(word) > 0):
            return True
        
        return False
    
    def search_images_with_enhanced_strategy(self, terms):
        """ê°•í™”ëœ ë‹¤ì¤‘ ì „ëµ ì´ë¯¸ì§€ ê²€ìƒ‰"""
        logger.info(f"ğŸ–¼ï¸ {len(terms)}ê°œ ìš©ì–´ì— ëŒ€í•œ ê°•í™”ëœ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘")
        
        term_image_mapping = {}
        successful_searches = 0
        
        for i, term in enumerate(terms, 1):
            logger.info(f"[{i}/{len(terms)}] '{term}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            
            # í™•ì¥ëœ ê²€ìƒ‰ ì „ëµ
            search_variants = [
                term,                               # ì›ë³¸
                term.replace(' ', '_'),             # ê³µë°± â†’ ì–¸ë”ìŠ¤ì½”ì–´
                term.replace(' ', ''),              # ê³µë°± ì œê±°
                term.lower(),                       # ì†Œë¬¸ì
                term.title(),                       # íƒ€ì´í‹€ ì¼€ì´ìŠ¤
                term.replace("'", ""),              # ì–´í¬ìŠ¤íŠ¸ë¡œí”¼ ì œê±°
                term.replace("-", " "),             # í•˜ì´í”ˆ â†’ ê³µë°±
                term.replace("&", "and"),           # & â†’ and
            ]
            
            # ë³µí•© ë‹¨ì–´ ë¶„í•´ ì „ëµ
            words = term.split()
            if len(words) > 1:
                # ê° ë‹¨ì–´ë³„ë¡œ ì‹œë„
                for word in words:
                    if len(word) > 3:  # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ
                        search_variants.append(word)
                
                # ë§ˆì§€ë§‰ ë‹¨ì–´ (ë³´í†µ ì•„ì´í…œ íƒ€ì…)
                if len(words[-1]) > 3:
                    search_variants.append(words[-1])
                
                # ì²« ë²ˆì§¸ + ë§ˆì§€ë§‰ ë‹¨ì–´ ì¡°í•©
                if len(words) > 2:
                    search_variants.append(f"{words[0]} {words[-1]}")
            
            # ì¤‘ë³µ ì œê±°
            search_variants = list(dict.fromkeys(search_variants))
            
            image_url = None
            for variant in search_variants:
                if variant and len(variant) > 2:
                    image_url = get_image_url_from_wiki(variant)
                    if image_url:
                        logger.info(f"âœ… ì´ë¯¸ì§€ ë°œê²¬ ('{variant}'): {term}")
                        break
            
            if image_url:
                term_image_mapping[term] = image_url
                successful_searches += 1
            else:
                logger.info(f"âŒ ì´ë¯¸ì§€ ì—†ìŒ: {term}")
        
        success_rate = (successful_searches / len(terms)) * 100 if terms else 0
        logger.info(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì™„ë£Œ: {successful_searches}/{len(terms)} ì„±ê³µ ({success_rate:.1f}%)")
        
        return term_image_mapping
    
    def insert_styled_images_into_markdown(self, korean_markdown, term_image_mapping):
        """ì¼ê´€ëœ ìŠ¤íƒ€ì¼ë§ìœ¼ë¡œ ì´ë¯¸ì§€ ì‚½ì…"""
        logger.info("ğŸ–¼ï¸ ì¼ê´€ëœ ìŠ¤íƒ€ì¼ë§ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì‚½ì… ì‹œì‘")
        
        content = korean_markdown
        inserted_count = 0
        
        # ì¼ê´€ëœ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼
        def create_styled_image(image_url, term):
            return (
                f'<img src="{image_url}" '
                f'alt="{term}" '
                f'title="{term}" '
                f'style="width: 64px; height: 64px; '
                f'object-fit: cover; '
                f'border: 2px solid #8B4513; '
                f'border-radius: 8px; '
                f'margin: 0 8px 4px 0; '
                f'vertical-align: middle; '
                f'box-shadow: 0 2px 4px rgba(0,0,0,0.3);">'
            )
        
        for term, image_url in term_image_mapping.items():
            if not image_url:
                continue
            
            # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ìš©ì–´ ì°¾ê¸°
            search_patterns = [
                # ê´„í˜¸ ì•ˆì˜ ì˜ë¬¸ëª…
                rf'\(({re.escape(term)})\)',
                # ê°•ì¡°ëœ ì˜ë¬¸ëª… 
                rf'\*\*{re.escape(term)}\*\*',
                # ì¼ë°˜ í…ìŠ¤íŠ¸ (ë‹¨ì–´ ê²½ê³„ ì‚¬ìš©)
                rf'\b{re.escape(term)}\b',
                # ì´íƒ¤ë¦­
                rf'_{re.escape(term)}_',
                # ì½”ë“œ ë¸”ë¡
                rf'`{re.escape(term)}`',
                # ë¦¬ìŠ¤íŠ¸ í•­ëª©
                rf'[-*]\s*\*\*{re.escape(term)}\*\*'
            ]
            
            for pattern in search_patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                match_found = False
                
                for match in matches:
                    # ì²« ë²ˆì§¸ ë§¤ì¹­ì—ë§Œ ì´ë¯¸ì§€ ì‚½ì…
                    styled_img = create_styled_image(image_url, term)
                    
                    # ë§¤ì¹­ëœ í…ìŠ¤íŠ¸ ì•ì— ì´ë¯¸ì§€ ì‚½ì…
                    start_pos = match.start()
                    content = content[:start_pos] + styled_img + '\n\n' + content[start_pos:]
                    inserted_count += 1
                    logger.info(f"âœ… ìŠ¤íƒ€ì¼ë§ëœ ì´ë¯¸ì§€ ì‚½ì…: {term}")
                    match_found = True
                    break
                
                if match_found:
                    break
        
        logger.info(f"ì´ {inserted_count}ê°œ ì¼ê´€ëœ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ")
        return content

def process_enhanced_perplexity_images(perplexity_raw_response, korean_markdown):
    """ì™„ì „ ê°•í™”ëœ Perplexity ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    logger.info("ğŸš€ ì™„ì „ ê°•í™”ëœ Perplexity ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì‹œì‘")
    
    try:
        # 1. Perplexity ì‘ë‹µì—ì„œ ì»¨í…ì¸  ì¶”ì¶œ
        if isinstance(perplexity_raw_response, str):
            perplexity_data = json.loads(perplexity_raw_response)
        else:
            perplexity_data = perplexity_raw_response
        
        perplexity_content = perplexity_data['choices'][0]['message']['content']
        logger.info(f"Perplexity ì‘ë‹µ ê¸¸ì´: {len(perplexity_content):,} ë¬¸ì")
        
        # 2. ê°•í™”ëœ ì˜ì–´ ìš©ì–´ ì¶”ì¶œ
        extractor = EnhancedPerplexityExtractor()
        terms, stats = extractor.extract_bg3_terms_from_perplexity(perplexity_content)
        
        if not terms:
            logger.warning("ì¶”ì¶œëœ BG3 ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return korean_markdown
        
        # 3. ê°•í™”ëœ ì´ë¯¸ì§€ ê²€ìƒ‰
        term_image_mapping = extractor.search_images_with_enhanced_strategy(terms)
        
        # 4. ì¼ê´€ëœ ìŠ¤íƒ€ì¼ë¡œ ì´ë¯¸ì§€ ì‚½ì…
        final_content = extractor.insert_styled_images_into_markdown(korean_markdown, term_image_mapping)
        
        logger.info("ğŸ¯ ì™„ì „ ê°•í™”ëœ Perplexity ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì™„ë£Œ")
        return final_content
        
    except Exception as e:
        logger.error(f"ê°•í™”ëœ Perplexity ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return korean_markdown 