#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import json
from .utils import logger
from .wiki_image_parser import get_image_url_from_wiki

def extract_english_terms_simple(perplexity_content):
    """Perplexityì—ì„œ ì˜ì–´ ìš©ì–´ë¥¼ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì¶”ì¶œ"""
    logger.info("ğŸ” ê°„ë‹¨í•œ ì˜ì–´ ìš©ì–´ ì¶”ì¶œ ì‹œì‘")
    
    english_terms = set()
    
    # 1. ê´„í˜¸ ì•ˆì˜ ì˜ì–´ ìš©ì–´ë“¤ (ê°€ì¥ í™•ì‹¤í•¨)
    bracket_pattern = r'\(([A-Z][A-Za-z\s\'\-]+)\)'
    bracket_matches = re.findall(bracket_pattern, perplexity_content)
    
    for term in bracket_matches:
        term = term.strip()
        if len(term) > 3 and not re.search(r'[ê°€-í£]', term):  # í•œê¸€ ì—†ê³  3ê¸€ì ì´ìƒ
            english_terms.add(term)
            logger.info(f"ê´„í˜¸ì—ì„œ ë°œê²¬: {term}")
    
    # 2. ì½œë¡  ë’¤ì˜ ì˜ì–´ ìš©ì–´ë“¤
    colon_pattern = r':\s*([A-Z][A-Za-z\s\'\-]+(?:\s+(?:Armor|Staff|Helm|Boots|Cloak|Ring|Amulet|Wounds|Word|Flame|Domain|Dwarf|Artisan|Caster))?)'
    colon_matches = re.findall(colon_pattern, perplexity_content)
    
    for term in colon_matches:
        term = term.strip()
        if len(term) > 3 and not re.search(r'[ê°€-í£]', term):
            english_terms.add(term)
            logger.info(f"ì½œë¡ ì—ì„œ ë°œê²¬: {term}")
    
    # 3. í™•ì‹¤í•œ BG3 ìš©ì–´ë“¤ ì§ì ‘ ì°¾ê¸°
    known_terms = [
        'Guidance', 'Resistance', 'Cure Wounds', 'Bless', 'Healing Word', 'Aid',
        'Spiritual Weapon', 'Sacred Flame', 'Spirit Guardians', 'Mass Healing Word',
        'Death Ward', 'Divine Strike', 'Mass Cure Wounds', 'Divine Intervention',
        'Heroes Feast', 'Life Domain', 'Shield Dwarf', 'Guild Artisan', 'War Caster',
        'Adamantine Splint Armor', 'Amulet of Greater Health', 'Helm of Brilliance',
        'Cloak of Protection', 'Ring of Regeneration', 'Preserve Life', 'Channel Divinity'
    ]
    
    for term in known_terms:
        if term in perplexity_content:
            english_terms.add(term)
            logger.info(f"í™•ì‹¤í•œ ìš©ì–´ ë°œê²¬: {term}")
    
    final_terms = list(english_terms)
    logger.info(f"ì´ ì¶”ì¶œëœ ì˜ì–´ ìš©ì–´: {len(final_terms)}ê°œ")
    
    return final_terms

def search_images_simple(terms):
    """ìš©ì–´ë“¤ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
    logger.info(f"ğŸ–¼ï¸ {len(terms)}ê°œ ìš©ì–´ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘")
    
    term_images = {}
    success_count = 0
    
    for i, term in enumerate(terms, 1):
        logger.info(f"[{i}/{len(terms)}] '{term}' ê²€ìƒ‰ ì¤‘...")
        
        # ê°„ë‹¨í•œ ê²€ìƒ‰ ì „ëµë“¤
        search_variants = [
            term,
            term.replace(' ', '_'),
            term.lower(),
            term.replace(' ', '')
        ]
        
        # ë³µí•© ë‹¨ì–´ëŠ” ë§ˆì§€ë§‰ ë‹¨ì–´ë„ ì‹œë„
        if ' ' in term:
            last_word = term.split()[-1]
            if len(last_word) > 3:
                search_variants.append(last_word)
        
        image_url = None
        for variant in search_variants:
            image_url = get_image_url_from_wiki(variant)
            if image_url:
                logger.info(f"âœ… ì´ë¯¸ì§€ ë°œê²¬: {term} (ê²€ìƒ‰ì–´: {variant})")
                break
        
        if image_url:
            term_images[term] = image_url
            success_count += 1
        else:
            logger.info(f"âŒ ì´ë¯¸ì§€ ì—†ìŒ: {term}")
    
    logger.info(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì™„ë£Œ: {success_count}/{len(terms)} ì„±ê³µ")
    return term_images

def insert_images_simple(korean_markdown, term_images):
    """í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì— ê°„ë‹¨í•˜ê²Œ ì´ë¯¸ì§€ ì‚½ì…"""
    logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚½ì… ì‹œì‘")
    
    content = korean_markdown
    inserted_count = 0
    
    # í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì—ì„œ ê´„í˜¸ ì•ˆì˜ ì˜ì–´ ìš©ì–´ë“¤ ì°¾ê¸°
    bracket_pattern = r'\(([A-Z][A-Za-z\s\'\-]+)\)'
    bracket_matches = re.findall(bracket_pattern, content)
    
    logger.info(f"í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì—ì„œ ë°œê²¬ëœ ê´„í˜¸ ì•ˆ ìš©ì–´ë“¤: {bracket_matches[:5]}...")
    
    for term, image_url in term_images.items():
        # í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì—ì„œ ì´ ìš©ì–´ê°€ ê´„í˜¸ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
        for bracket_term in bracket_matches:
            if term.lower() == bracket_term.lower() or term == bracket_term:
                # ê°„ë‹¨í•œ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ (ë” ì‘ê²Œ)
                img_tag = f'<img src="{image_url}" alt="{term}" title="{term}" style="width: 48px; height: 48px; border: 2px solid #8B4513; border-radius: 6px; margin-left: 8px; vertical-align: middle; display: inline-block;">'
                
                # ê´„í˜¸ ì•ˆì˜ ìš©ì–´ ë’¤ì— ì´ë¯¸ì§€ ì‚½ì… (ì¤„ë°”ê¿ˆ ì—†ì´)
                pattern = rf'\({re.escape(bracket_term)}\)'
                if re.search(pattern, content, re.IGNORECASE):
                    content = re.sub(pattern, f'({bracket_term}) {img_tag}', content, count=1, flags=re.IGNORECASE)
                    inserted_count += 1
                    logger.info(f"âœ… ì´ë¯¸ì§€ ì‚½ì…: {term} (ê´„í˜¸: {bracket_term})")
                    break
    
    # ì¶”ê°€: í•œêµ­ì–´ ìš©ì–´ì™€ ë§¤ì¹­ ì‹œë„
    korean_mappings = {
        'Guidance': ['ê°€ì´ë˜ìŠ¤', 'ì§€ë„'],
        'Bless': ['ì¶•ë³µ'],
        'Cure Wounds': ['ìƒì²˜', 'ì¹˜ìœ '],
        'Healing Word': ['ì¹˜ìœ ', 'íšŒë³µ'],
        'Sacred Flame': ['ì„±ìŠ¤ëŸ¬ìš´', 'í™”ì—¼'],
        'Spirit Guardians': ['ì˜í˜¼', 'ìˆ˜í˜¸ì'],
        'Life Domain': ['ìƒëª…', 'ì˜ì—­'],
        'Shield Dwarf': ['ë°©íŒ¨', 'ë“œì›Œí”„'],
        'War Caster': ['ì „ìŸ', 'ìˆ ì‚¬']
    }
    
    for term, image_url in term_images.items():
        if term in korean_mappings:
            for korean_word in korean_mappings[term]:
                if korean_word in content and term not in content:
                    img_tag = f'<img src="{image_url}" alt="{term}" title="{term}" style="width: 32px; height: 32px; border: 2px solid #8B4513; border-radius: 4px; margin-left: 6px; vertical-align: middle; display: inline-block;">'
                    
                    # í•œêµ­ì–´ ë‹¨ì–´ ë’¤ì— ì´ë¯¸ì§€ ì‚½ì… (ì¤„ë°”ê¿ˆ ì—†ì´)
                    content = re.sub(f'({korean_word})', f'\\1 {img_tag}', content, count=1)
                    inserted_count += 1
                    logger.info(f"âœ… í•œêµ­ì–´ ë§¤ì¹­ ì´ë¯¸ì§€ ì‚½ì…: {term} -> {korean_word}")
                    break
    
    logger.info(f"ì´ {inserted_count}ê°œ ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ")
    return content

def process_simple_perplexity_images(korean_markdown, perplexity_file_path):
    """
    Perplexity íŒŒì¼ì„ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ë¥¼ ì‚½ì…í•˜ëŠ” ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°
    
    Args:
        korean_markdown: í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
        perplexity_file_path: Perplexity ì›ë³¸ ì‘ë‹µ JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        str: ì´ë¯¸ì§€ê°€ ì‚½ì…ëœ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´
    """
    logger.info("ğŸš€ ìƒˆë¡œìš´ ê°„ë‹¨í•œ Perplexity ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì‹œì‘!")
    
    try:
        # 1. Perplexity ì›ë³¸ ì‘ë‹µ ë¡œë“œ
        with open(perplexity_file_path, 'r', encoding='utf-8') as f:
            perplexity_data = json.load(f)
        
        perplexity_content = perplexity_data['choices'][0]['message']['content']
        logger.info("âœ… Perplexity ì›ë³¸ ì‘ë‹µ ë¡œë“œ ì™„ë£Œ")
        
        # 2. ì˜ì–´ ìš©ì–´ ì¶”ì¶œ
        english_terms = extract_english_terms_simple(perplexity_content)
        logger.info(f"âœ… ì˜ì–´ ìš©ì–´ ì¶”ì¶œ ì™„ë£Œ: {len(english_terms)}ê°œ")
        
        # 3. ì´ë¯¸ì§€ ê²€ìƒ‰
        term_images = search_images_simple(english_terms)
        logger.info(f"âœ… ì´ë¯¸ì§€ ê²€ìƒ‰ ì™„ë£Œ: {len(term_images)}ê°œ")
        
        # 4. ì´ë¯¸ì§€ ì‚½ì…
        final_markdown = insert_images_simple(korean_markdown, term_images)
        logger.info("âœ… ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ")
        
        return final_markdown
        
    except Exception as e:
        logger.error(f"âŒ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return korean_markdown 