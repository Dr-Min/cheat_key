#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
from .skill_extractor import extract_bg3_terms_from_source, create_term_mapping, get_image_search_terms
from .wiki_image_parser import get_image_url_from_wiki
from .utils import logger

def process_images_with_source_accuracy(english_build_info, korean_content):
    """
    Perplexity ì›ë³¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì´ë¯¸ì§€ ì²˜ë¦¬
    
    Args:
        english_build_info: Perplexityì—ì„œ ë°›ì€ ì›ë³¸ ì˜ì–´ ë¹Œë“œ ì •ë³´
        korean_content: ë²ˆì—­ëœ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
        
    Returns:
        str: ì´ë¯¸ì§€ê°€ ì‚½ì…ëœ ìµœì¢… ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
    """
    logger.info("ğŸ” ì›ë³¸ ì†ŒìŠ¤ ê¸°ë°˜ ì •í™•í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘")
    
    # 1. ì›ë³¸ ì˜ì–´ ì •ë³´ì—ì„œ ì •í™•í•œ BG3 ìš©ì–´ë“¤ ì¶”ì¶œ
    logger.info("1ï¸âƒ£ ì›ë³¸ ì˜ì–´ ë¹Œë“œ ì •ë³´ì—ì„œ BG3 ìš©ì–´ ì¶”ì¶œ...")
    extracted_terms = extract_bg3_terms_from_source(english_build_info)
    
    # 2. ì˜ì–´-í•œêµ­ì–´ ìš©ì–´ ë§¤í•‘ ìƒì„±
    logger.info("2ï¸âƒ£ ì˜ì–´-í•œêµ­ì–´ ìš©ì–´ ë§¤í•‘ ìƒì„±...")
    term_mapping = create_term_mapping(extracted_terms, korean_content)
    
    # 3. ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ ìš©ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    logger.info("3ï¸âƒ£ ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ ìš©ì–´ ìƒì„±...")
    search_terms = get_image_search_terms(extracted_terms)
    
    # 4. ê° ìš©ì–´ë³„ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ìˆ˜ì§‘
    logger.info("4ï¸âƒ£ ì •í™•í•œ ì˜ë¬¸ëª…ìœ¼ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
    image_collection = {}
    search_success = 0
    
    for term in search_terms[:20]:  # ìƒìœ„ 20ê°œë¡œ ì œí•œ
        logger.info(f"'{term}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
        
        img_url = get_image_url_from_wiki(term)
        if img_url:
            korean_name = term_mapping.get(term, term)  # í•œêµ­ì–´ëª…ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì˜ì–´ëª…
            
            image_collection[term] = {
                'url': img_url,
                'korean_name': korean_name,
                'search_confidence': 'high'  # ì›ë³¸ì—ì„œ ì¶”ì¶œí–ˆìœ¼ë¯€ë¡œ ë†’ì€ ì‹ ë¢°ë„
            }
            search_success += 1
            logger.info(f"âœ… {term}: ì´ë¯¸ì§€ ë°œê²¬ (í•œêµ­ì–´: {korean_name})")
        else:
            logger.warning(f"âŒ {term}: ì´ë¯¸ì§€ ì°¾ì§€ ëª»í•¨")
        
        # API ìš”ì²­ ì œí•œ ì¤€ìˆ˜
        time.sleep(0.8)
    
    search_rate = (search_success / len(search_terms[:20])) * 100 if search_terms else 0
    logger.info(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì™„ë£Œ: {search_success}/{len(search_terms[:20])} ì„±ê³µ ({search_rate:.1f}%)")
    
    # 5. ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì‚½ì…
    logger.info("5ï¸âƒ£ ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì‚½ì… ì¤‘...")
    final_content = insert_images_to_korean_content(korean_content, image_collection, term_mapping)
    
    # 6. BG3 í—¤ë” ì´ë¯¸ì§€ ì¶”ê°€
    final_content = add_bg3_header_image(final_content)
    
    logger.info(f"ğŸ¯ ì •í™•ë„ ê°œì„  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ - {len(image_collection)}ê°œ ì´ë¯¸ì§€ ì‚½ì…")
    
    return final_content

def insert_images_to_korean_content(korean_content, image_collection, term_mapping):
    """
    í•œêµ­ì–´ ì½˜í…ì¸ ì— ì •í™•í•œ ì´ë¯¸ì§€ë“¤ì„ ì‚½ì…
    
    Args:
        korean_content: í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
        image_collection: ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ ì •ë³´
        term_mapping: ì˜ì–´-í•œêµ­ì–´ ìš©ì–´ ë§¤í•‘
        
    Returns:
        str: ì´ë¯¸ì§€ê°€ ì‚½ì…ëœ ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
    """
    import re
    
    lines = korean_content.split('\n')
    new_content = []
    inserted_images = set()
    
    # ì—­ë§¤í•‘ ìƒì„± (í•œêµ­ì–´ â†’ ì˜ì–´)
    reverse_mapping = {v: k for k, v in term_mapping.items()}
    
    for line in lines:
        line_modified = False
        
        # í•œêµ­ì–´ ìš©ì–´ë“¤ê³¼ ë§¤ì¹˜í•´ì„œ ì´ë¯¸ì§€ ì‚½ì…
        for korean_term, english_term in reverse_mapping.items():
            if english_term in image_collection and english_term not in inserted_images:
                # í•œêµ­ì–´ ìš©ì–´ê°€ ë¼ì¸ì— í¬í•¨ë˜ì–´ ìˆê³ , ê°•ì¡° í‘œì‹œë˜ì–´ ìˆëŠ” ê²½ìš°
                if korean_term in line and ('**' in line or '*' in line):
                    img_info = image_collection[english_term]
                    
                    # ì´ë¯¸ì§€ íƒœê·¸ ìƒì„±
                    img_markdown = (
                        f"<img src=\"{img_info['url']}\" "
                        f"alt=\"{english_term}\" "
                        f"title=\"{korean_term}\" "
                        f"width=\"120\" "
                        f"style=\"margin-right: 10px; vertical-align: middle;\">"
                    )
                    
                    # ì´ë¯¸ì§€ë¥¼ ë¼ì¸ ì•ì— ì¶”ê°€
                    new_content.append(img_markdown)
                    new_content.append(line)
                    
                    inserted_images.add(english_term)
                    line_modified = True
                    logger.debug(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚½ì…: {korean_term} ({english_term})")
                    break
        
        # ì˜ì–´ ìš©ì–´ê°€ ì§ì ‘ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš°ë„ ì²´í¬
        if not line_modified:
            for english_term in image_collection:
                if english_term in line and english_term not in inserted_images:
                    if '**' in line or '*' in line:
                        img_info = image_collection[english_term]
                        
                        img_markdown = (
                            f"<img src=\"{img_info['url']}\" "
                            f"alt=\"{english_term}\" "
                            f"title=\"{img_info['korean_name']}\" "
                            f"width=\"120\" "
                            f"style=\"margin-right: 10px; vertical-align: middle;\">"
                        )
                        
                        new_content.append(img_markdown)
                        new_content.append(line)
                        
                        inserted_images.add(english_term)
                        line_modified = True
                        logger.debug(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‚½ì…: {english_term}")
                        break
        
        # ì´ë¯¸ì§€ê°€ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì›ë˜ ë¼ì¸ ì¶”ê°€
        if not line_modified:
            new_content.append(line)
    
    logger.info(f"ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ: {len(inserted_images)}ê°œ ì‚½ì…ë¨")
    
    return '\n'.join(new_content)

def add_bg3_header_image(content):
    """BG3 í—¤ë” ì´ë¯¸ì§€ ì¶”ê°€"""
    header_image = "https://i.namu.wiki/i/IxWGCIu4G78HZv1d2AU_C5taEO8i-iT_aEbh5YbPAz73yIS3gFGB-Fj6EvL4Z-jmjcFIvWhr2XOxN0-sdmH31g.webp"
    header_markdown = f"<img src=\"{header_image}\" alt=\"BG3 í—¤ë” ì´ë¯¸ì§€\" width=\"100%\" style=\"margin-bottom: 20px;\">\n\n"
    
    # ì²« ë²ˆì§¸ ì œëª© ì°¾ì•„ì„œ ìœ„ì— í—¤ë” ì´ë¯¸ì§€ ì‚½ì…
    import re
    first_heading = re.search(r'^#\s+.*$', content, re.MULTILINE)
    if first_heading:
        heading_pos = first_heading.start()
        content = content[:heading_pos] + header_markdown + content[heading_pos:]
    else:
        content = header_markdown + content
    
    return content

def save_extraction_results(build_name, extracted_terms, image_collection):
    """ì¶”ì¶œ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (ë””ë²„ê¹…ìš©)"""
    import json
    from datetime import datetime
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"extraction_results_{build_name.replace(' ', '_')}_{timestamp}.json"
    
    results = {
        "build_name": build_name,
        "timestamp": timestamp,
        "extracted_terms": extracted_terms,
        "image_collection": image_collection,
        "statistics": {
            "total_terms": sum(len(terms) for terms in extracted_terms.values()),
            "images_found": len(image_collection),
            "success_rate": len(image_collection) / sum(len(terms) for terms in extracted_terms.values()) * 100 if extracted_terms else 0
        }
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info(f"ì¶”ì¶œ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return filename
    except Exception as e:
        logger.error(f"ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return None 