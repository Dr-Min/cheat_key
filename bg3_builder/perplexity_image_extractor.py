#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import json
from .utils import logger
from .wiki_image_parser import get_image_url_from_wiki

class PerplexityImageExtractor:
    """Perplexity ì›ë³¸ ì‘ë‹µì—ì„œ ì˜ì–´ BG3 ìš©ì–´ë¥¼ ì¶”ì¶œí•˜ê³  ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # Perplexityì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” BG3 ìš©ì–´ íŒ¨í„´ë“¤
        self.bg3_patterns = [
            # ê´„í˜¸ ì•ˆì˜ ì˜ë¬¸ëª…: ì¬ë”ì›¨ì´ë¸Œ(Thunderwave)
            r'[ê°€-í£\s]+\(([A-Z][A-Za-z\s\'\-]+)\)',
            
            # ì˜ë¬¸ëª… ì§ì ‘ ì–¸ê¸‰: **Thunderwave**, Lightning Bolt ë“±
            r'\*\*([A-Z][A-Za-z\s\'\-]+)\*\*',
            
            # ì½œë¡  í›„ ì˜ë¬¸ëª…: **ì£¼ë¬¸:** ì¬ë”ì›¨ì´ë¸Œ(Thunderwave)
            r':\s*[ê°€-í£\s]*\(([A-Z][A-Za-z\s\'\-]+)\)',
            
            # ë‹¨ë… ì˜ë¬¸ëª… (The Blood of Lathander ê°™ì€)
            r'\b(The\s+[A-Z][A-Za-z\s\'\-]+)\b',
            r'\b([A-Z][a-z]+\s+of\s+[A-Z][A-Za-z\s\'\-]+)\b',
            
            # ì¼ë°˜ BG3 ìš©ì–´ íŒ¨í„´
            r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,3})\b',
            
            # íŠ¹ìˆ˜ í˜•íƒœë“¤
            r'([A-Z][A-Za-z\'\-]+(?:\s+[A-Z][A-Za-z\'\-]+)*)\s*\[?\d*\]?'
        ]
        
        # ì œì™¸í•  ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤
        self.excluded_words = {
            'general': ['Game', 'Build', 'Guide', 'Level', 'Act', 'Patch', 'Steam', 'Forum', 
                       'User', 'Community', 'Expert', 'Professional', 'Best', 'Top', 'Main'],
            'korean': ['ê¸°ì¤€', 'ì ìš©', 'ì´ìœ ', 'ë¬´ë£Œ', 'íšë“', 'ë¯¼ì²©', 'ë§¤ë ¥', 'ì¥ì ', 'ë‹¨ì ', 
                      'ì½¤ë³´', 'ê°•í™”', 'í™œìš©', 'ìš°ì„ ìˆœìœ„', 'ìµœì í™”', 'ê¸°ë°˜'],
            'numbers': ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA', 'AC', 'DC']
        }
    
    def extract_english_terms_from_perplexity(self, perplexity_content):
        """Perplexity ì‘ë‹µì—ì„œ ì˜ì–´ BG3 ìš©ì–´ë“¤ì„ ì¶”ì¶œ"""
        logger.info("ğŸ” Perplexity ì‘ë‹µì—ì„œ ì˜ì–´ BG3 ìš©ì–´ ì¶”ì¶œ ì‹œì‘")
        
        all_terms = set()
        extraction_stats = {}
        
        for i, pattern in enumerate(self.bg3_patterns, 1):
            matches = re.findall(pattern, perplexity_content, re.MULTILINE)
            valid_matches = []
            
            for match in matches:
                if isinstance(match, tuple):
                    term = match[0] if match[0] else (match[1] if len(match) > 1 else '')
                else:
                    term = match
                
                term = term.strip()
                
                # ìœ íš¨ì„± ê²€ì¦
                if self.is_valid_bg3_term(term):
                    all_terms.add(term)
                    valid_matches.append(term)
            
            extraction_stats[f"íŒ¨í„´_{i}"] = {
                "total": len(matches),
                "valid": len(valid_matches),
                "terms": valid_matches[:5]  # ìƒ˜í”Œë§Œ
            }
            
            logger.info(f"íŒ¨í„´ {i}: {len(valid_matches)}/{len(matches)} ìœ íš¨")
        
        logger.info(f"ì´ ì¶”ì¶œëœ ì˜ì–´ ìš©ì–´: {len(all_terms)}ê°œ")
        
        # ì¶”ì¶œëœ ìš©ì–´ë“¤ ë¡œê¹…
        if all_terms:
            sorted_terms = sorted(all_terms)
            logger.info(f"ì¶”ì¶œëœ BG3 ìš©ì–´ë“¤: {', '.join(sorted_terms[:15])}...")
        
        return list(all_terms), extraction_stats
    
    def is_valid_bg3_term(self, term):
        """BG3 ê´€ë ¨ ìœ íš¨í•œ ìš©ì–´ì¸ì§€ ê²€ì¦"""
        # ê¸¸ì´ ì²´í¬
        if len(term) < 3 or len(term) > 40:
            return False
        
        # ì œì™¸ ë‹¨ì–´ ì²´í¬
        term_words = term.split()
        for word in term_words:
            for category, excluded in self.excluded_words.items():
                if word in excluded:
                    return False
        
        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if term.isdigit():
            return False
        
        # í•œê¸€ì´ í¬í•¨ëœ ê²½ìš° ì œì™¸ (ì˜ì–´ë§Œ)
        if re.search(r'[ê°€-í£]', term):
            return False
        
        # íŠ¹ìˆ˜ë¬¸ì ê³¼ë‹¤ ì œì™¸
        special_chars = len(re.findall(r'[^A-Za-z\s\'\-]', term))
        if special_chars > 2:
            return False
        
        # BG3ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ì²´í¬
        # 1. ì²« ê¸€ì ëŒ€ë¬¸ì + ì ì ˆí•œ ê¸¸ì´
        if re.match(r'^[A-Z][a-z]', term) and len(term) > 4:
            return True
        
        # 2. "The X of Y" íŒ¨í„´
        if re.match(r'^The\s+[A-Z][a-z]+\s+of\s+[A-Z]', term):
            return True
        
        # 3. ë³µí•© ë‹¨ì–´ (Lightning Bolt, Magic Missile ë“±)
        if len(term_words) >= 2 and all(word[0].isupper() for word in term_words):
            return True
        
        return False
    
    def search_images_for_terms(self, terms):
        """ì¶”ì¶œëœ ìš©ì–´ë“¤ì— ëŒ€í•´ ì´ë¯¸ì§€ ê²€ìƒ‰"""
        logger.info(f"ğŸ–¼ï¸ {len(terms)}ê°œ ìš©ì–´ì— ëŒ€í•œ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘")
        
        term_image_mapping = {}
        successful_searches = 0
        
        for i, term in enumerate(terms, 1):
            logger.info(f"[{i}/{len(terms)}] '{term}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            
            # ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ
            search_variants = [
                term,  # ì›ë³¸
                term.replace(' ', '_'),  # ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ
                term.lower(),  # ì†Œë¬¸ì
                term.title(),  # íƒ€ì´í‹€ ì¼€ì´ìŠ¤
                term.replace("'", ""),  # ì–´í¬ìŠ¤íŠ¸ë¡œí”¼ ì œê±°
                term.replace("-", " "),  # í•˜ì´í”ˆì„ ê³µë°±ìœ¼ë¡œ
            ]
            
            # ë³µí•© ë‹¨ì–´ì¸ ê²½ìš° ì²« ë²ˆì§¸ ë‹¨ì–´ë„ ì‹œë„
            words = term.split()
            if len(words) > 1:
                search_variants.append(words[0])
                search_variants.append(words[-1])  # ë§ˆì§€ë§‰ ë‹¨ì–´ë„
            
            image_url = None
            for variant in search_variants:
                if variant and len(variant) > 2:
                    image_url = get_image_url_from_wiki(variant)
                    if image_url:
                        logger.info(f"âœ… ì´ë¯¸ì§€ ë°œê²¬ ('{variant}'): {term}")
                        break
            
            if image_url:
                term_image_mapping[term] = image_url
                successful_searches += 1
            else:
                logger.info(f"âŒ ì´ë¯¸ì§€ ì—†ìŒ: {term}")
        
        success_rate = (successful_searches / len(terms)) * 100 if terms else 0
        logger.info(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì™„ë£Œ: {successful_searches}/{len(terms)} ì„±ê³µ ({success_rate:.1f}%)")
        
        return term_image_mapping
    
    def insert_images_into_korean_markdown(self, korean_markdown, term_image_mapping):
        """í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì— ì˜ì–´ ìš©ì–´ ê¸°ë°˜ ì´ë¯¸ì§€ ì‚½ì…"""
        logger.info("ğŸ–¼ï¸ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì‚½ì… ì‹œì‘")
        
        content = korean_markdown
        inserted_count = 0
        
        for term, image_url in term_image_mapping.items():
            if not image_url:
                continue
            
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ì˜ì–´ ìš©ì–´ ì°¾ê¸° (ë‹¤ì–‘í•œ íŒ¨í„´)
            search_patterns = [
                # ê´„í˜¸ ì•ˆì˜ ì˜ë¬¸ëª…
                rf'\(({re.escape(term)})\)',
                # ê°•ì¡°ëœ ì˜ë¬¸ëª…
                rf'\*\*{re.escape(term)}\*\*',
                # ì¼ë°˜ í…ìŠ¤íŠ¸
                rf'\b{re.escape(term)}\b',
                # ì´íƒ¤ë¦­
                rf'_{re.escape(term)}_',
                # ì½”ë“œ ë¸”ë¡
                rf'`{re.escape(term)}`'
            ]
            
            for pattern in search_patterns:
                if re.search(pattern, content):
                    # ì´ë¯¸ì§€ ë§ˆí¬ë‹¤ìš´ ìƒì„±
                    img_markdown = f'<img src="{image_url}" alt="{term}" title="{term}" style="margin-right: 10px; vertical-align: middle;" style="width: 120px;">'
                    
                    # ì²« ë²ˆì§¸ ë§¤ì¹­ì—ë§Œ ì´ë¯¸ì§€ ì‚½ì…
                    content = re.sub(pattern, f'{img_markdown}\n\n\\g<0>', content, count=1)
                    inserted_count += 1
                    logger.info(f"âœ… ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ: {term}")
                    break
        
        logger.info(f"ì´ {inserted_count}ê°œ ì´ë¯¸ì§€ ì‚½ì… ì™„ë£Œ")
        return content

def process_perplexity_based_images(perplexity_raw_response, korean_markdown):
    """Perplexity ê¸°ë°˜ ë™ì  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    logger.info("ğŸš€ Perplexity ê¸°ë°˜ ë™ì  ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì‹œì‘")
    
    try:
        # 1. Perplexity ì‘ë‹µì—ì„œ ì»¨í…ì¸  ì¶”ì¶œ
        if isinstance(perplexity_raw_response, str):
            # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            perplexity_data = json.loads(perplexity_raw_response)
        else:
            # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
            perplexity_data = perplexity_raw_response
        
        # content ì¶”ì¶œ
        perplexity_content = perplexity_data['choices'][0]['message']['content']
        logger.info(f"Perplexity ì‘ë‹µ ê¸¸ì´: {len(perplexity_content):,} ë¬¸ì")
        
        # 2. ì˜ì–´ ìš©ì–´ ì¶”ì¶œ
        extractor = PerplexityImageExtractor()
        terms, stats = extractor.extract_english_terms_from_perplexity(perplexity_content)
        
        if not terms:
            logger.warning("ì¶”ì¶œëœ BG3 ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return korean_markdown
        
        # 3. ì´ë¯¸ì§€ ê²€ìƒ‰
        term_image_mapping = extractor.search_images_for_terms(terms)
        
        # 4. í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì‚½ì…
        final_content = extractor.insert_images_into_korean_markdown(korean_markdown, term_image_mapping)
        
        logger.info("ğŸ¯ Perplexity ê¸°ë°˜ ë™ì  ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì™„ë£Œ")
        return final_content
        
    except Exception as e:
        logger.error(f"Perplexity ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return korean_markdown 